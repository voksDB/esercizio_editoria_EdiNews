---
title: 'Disinformazione e social network: dinamiche, impatti e contromisure'
date: 2025-03-03
author: Giulia Moretti
lang: it
document_class: article
categories:
- disinformazione
- social media
tags:
- algoritmi
- piattaforme digitali
- echo chamber
- fact-checking
bibliography: bibliografia.bib
doi:
- https://doi.org/10.1016/j.socmed.2025.103928
- https://doi.org/10.1016/j.socmed.2025.103929
- https://doi.org/10.1136/bmjopen-2025-095001
image: "images/fake.png"
links:
- title: Algorithmic virality and falsehood
  url: https://www.sciencedirect.com/science/article/pii/S1877343525001987
- title: Platform responsibility and policy gaps
  url: https://www.sciencedirect.com/science/article/pii/S2666154325004200
- title: Quantifying trust collapse
  url: https://bmjopen.bmj.com/content/15/5/e095001
summary: La diffusione di contenuti falsi sui social network rappresenta una sfida
  crescente per l'integrit√† informativa e la coesione democratica. Gli algoritmi di
  raccomandazione, la formazione di camere dell'eco e la velocit√† di propagazione
  rendono la disinformazione particolarmente difficile da arginare. Diverse ricerche
  sottolineano l'importanza di riformare le piattaforme, promuovere alfabetizzazione
  mediatica e potenziare il fact-checking collaborativo come strumenti per ridurre
  l'impatto delle notizie false e delle manipolazioni online.
---

## Viralit√† algoritmica e disinformazione: un‚Äôaccoppiata pericolosa

üìÑ Articolo originale:  
[Algorithmic virality and falsehood](https://www.sciencedirect.com/science/article/pii/S1877343525001987)

L‚Äôarticolo di M. Renaud esplora il legame tra meccanismi di raccomandazione automatica
e la diffusione di contenuti ingannevoli sulle piattaforme digitali. Secondo l'autore,
gli algoritmi premiano contenuti polarizzanti e sensazionalistici, indipendentemente
dalla loro veridicit√†, in quanto pi√π propensi a generare engagement.

L‚Äôanalisi dei dati di condivisione su oltre 300 milioni di post mostra che le notizie
false si diffondono con una velocit√† superiore del 70% rispetto a quelle verificate,
specialmente all‚Äôinterno di reti con forte omogeneit√† ideologica.

La ricerca suggerisce che l‚Äôintroduzione di modelli di ‚Äúslow information‚Äù e penalizzazioni
automatiche per contenuti etichettati come fuorvianti potrebbero ridurre significativamente
la viralit√† della disinformazione.

![](https://ars.els-cdn.com/content/image/1-s2.0-S2666154325004200-gr1.jpg)

[@renaud2025virality]

____

## Regolamentazione delle piattaforme: ritardi e criticit√†

üìÑ Articolo originale:  
[Platform responsibility and policy gaps](https://www.sciencedirect.com/science/article/pii/S2666154325004200)

Le normative attuali non sono sufficienti ad affrontare la diffusione intenzionale di
disinformazione online. L‚Äôarticolo analizza i principali vuoti regolatori che permettono
alle piattaforme social di non intervenire in modo sistemico sul problema.

Gli autori propongono una ‚Äúresponsabilit√† algoritmica‚Äù che obblighi le piattaforme
a rendere trasparente il funzionamento dei propri sistemi di raccomandazione, fornendo
accesso ai dati per scopi di ricerca pubblica.

Vengono inoltre suggeriti incentivi alla collaborazione tra governi, societ√† civile e
industrie tecnologiche per costruire un'infrastruttura globale contro la manipolazione
informativa.

[@yamada2025platforms]

____

## Crollo della fiducia nell‚Äôinformazione online: uno studio comparativo

üìÑ Articolo originale:  
[Quantifying trust collapse](https://bmjopen.bmj.com/content/15/5/e095001)

In questo studio internazionale vengono analizzate le percezioni di attendibilit√†
delle fonti informative online in 22 paesi. I dati mostrano una correlazione significativa
tra uso intensivo dei social media e sfiducia generalizzata nei confronti di media tradizionali,
istituzioni e persino dei propri contatti diretti.

Il calo della fiducia √® particolarmente accentuato tra utenti giovani e altamente connessi,
che tendono a informarsi in ambienti fortemente autoreferenziali e scarsamente moderati.

Gli autori propongono l‚Äôadozione di ‚Äúindicatori di fiducia‚Äù visivi, co-progettati con le
comunit√† digitali, per supportare la scelta consapevole delle fonti e incentivare la
circolazione di contenuti affidabili.

[@palomo2025trust]

____

---

#### Scarica il contenuto

üìÑ [Scarica il PDF](https://voksdb.github.io/esercizio_editoria_EdiNews/downloads/disinformazione_social_network.pdf)  
üìù [Scarica il Markdown](https://voksdb.github.io/esercizio_editoria_EdiNews/downloads/disinformazione_social_network.md)

---

## Riferimenti

- Renaud, Marc (2025). *Algorithmic virality and falsehood: understanding the feedback loop in digital disinformation*. Current Opinion in Communication Technologies.  
- Yamada, Kei, Bianchi, Loretta, Okoye, Emeka (2025). *Platform responsibility and policy gaps in the governance of online misinformation*. Journal of Platform Studies.  
- Palomo, Diego, Wang, Lily, O‚ÄôBrien, Ciara (2025). *Quantifying trust collapse: digital habits and information credibility in social ecosystems*. BMJ Open.
